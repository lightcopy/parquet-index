language: scala
sudo: false
cache:
  directories:
    - $HOME/.ivy2
    - $HOME/.sbt/launchers
    - $HOME/.cache/spark-versions
matrix:
  include:
    - jdk: openjdk7
      scala: 2.10.5
      env: TEST_SPARK_VERSION="2.0.0" TEST_SPARK_RELEASE="NA"
    - jdk: openjdk7
      scala: 2.10.5
      env: TEST_SPARK_VERSION="2.0.1" TEST_SPARK_RELEASE="NA"
    - jdk: openjdk7
      scala: 2.11.7
      env: TEST_SPARK_VERSION="2.0.0" TEST_SPARK_RELEASE="spark-2.0.0-bin-hadoop2.6"
    - jdk: openjdk7
      scala: 2.11.7
      env: TEST_SPARK_VERSION="2.0.1" TEST_SPARK_RELEASE="spark-2.0.1-bin-hadoop2.6"
    - jdk: openjdk7
      scala: 2.11.7
      env: TEST_SPARK_VERSION="2.0.2" TEST_SPARK_RELEASE="spark-2.0.2-bin-hadoop2.6"
script:
  - sbt ++$TRAVIS_SCALA_VERSION scalastyle
  - sbt ++$TRAVIS_SCALA_VERSION "test:scalastyle"
  - sbt -Dspark.testVersion=$TEST_SPARK_VERSION ++$TRAVIS_SCALA_VERSION coverage test
  - sbt ++$TRAVIS_SCALA_VERSION assembly
  - sbt ++$TRAVIS_SCALA_VERSION package
  - ./bin/setup-spark $TEST_SPARK_RELEASE $HOME/.cache/spark-versions
  - SPARK_HOME=$HOME/.cache/spark-versions/$TEST_SPARK_RELEASE ./bin/run-python-tests
after_success:
  - sbt coverageReport coveralls
